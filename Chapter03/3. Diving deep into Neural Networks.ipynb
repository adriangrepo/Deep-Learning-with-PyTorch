{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers : Fundamental blocks of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear, ReLU\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear (dense/fully connected) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8729, -0.5990,  0.1757,  0.6025, -0.7942]],\n",
       "        grad_fn=<AddmmBackward>), torch.Size([1, 5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(1,10)\n",
    "myLayer = Linear(in_features=10,out_features=5,bias=True) \n",
    "myLayer(inp), myLayer(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.2369,  0.0671,  0.2368,  0.0310,  0.1671,  0.1415,  0.0013,  0.2144,\n",
       "          -0.1217, -0.0554],\n",
       "         [ 0.1078,  0.2038,  0.1662, -0.0033,  0.2745, -0.1021,  0.0875,  0.2908,\n",
       "           0.1262,  0.2703],\n",
       "         [-0.2449,  0.0744,  0.1469, -0.2009, -0.2778,  0.2306,  0.1444, -0.1536,\n",
       "           0.0673, -0.0356],\n",
       "         [ 0.2840, -0.2210, -0.2120,  0.0253, -0.0694, -0.2035,  0.0589,  0.1176,\n",
       "          -0.3014,  0.0294],\n",
       "         [-0.1369,  0.0943,  0.0795,  0.2927, -0.0427, -0.1963,  0.1683, -0.2761,\n",
       "           0.1941, -0.2954]], requires_grad=True), torch.Size([5, 10]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.weight, myLayer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([ 0.0230, -0.1650,  0.2917, -0.2488, -0.2449], requires_grad=True),\n",
       " 'torch.FloatTensor')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.bias, myLayer.bias.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3072,  0.5236]], grad_fn=<AddmmBackward>), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer1 = Linear(10,5)\n",
    "myLayer2 = Linear(5,2)\n",
    "myLayer2(myLayer1(inp)), myLayer2(myLayer1(inp)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Non-linear Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = torch.Tensor([[1,2,-1,-1]])\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRelu = ReLU()\n",
    "myRelu(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = torch.Tensor([[1,2,-1,-1]])\n",
    "f = F.relu(sample_data) # Much simpler.\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyFirstNetwork(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(MyFirstNetwork,self).__init__() \n",
    "        self.layer1 = nn.Linear(input_size,hidden_size) \n",
    "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "    def __forward__(self,input): \n",
    "        out = self.layer1(input) \n",
    "        out = nn.ReLU(out)\n",
    "        out = self.layer2(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True) \n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(true_label, prediction):\n",
    "    #loss will be high when predictions are bad and low when predictions are good\n",
    "    if true_label == 1:\n",
    "        return -log(prediction)\n",
    "    else:\n",
    "        return -log(1 - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True) \n",
    "target = torch.LongTensor(3).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch.optim as optim\\noptimizer = optim.SGD(model.parameters(), lr = 0.01)\\nfor input, target in dataset:\\n    #call zero_grad() inside our loop, as the parameters will accumulate the gradients created during the previous optimizer call\\n    optimizer.zero_grad()\\n    output = model(input)\\n    loss = loss_fn(output, target)\\n    loss.backward()\\n    optimizer.step()\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for demo\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "for input, target in dataset:\n",
    "    #call zero_grad() inside our loop, as the parameters will accumulate the gradients created during the previous optimizer call\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
