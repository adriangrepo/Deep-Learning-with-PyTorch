{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchtext import data,datasets\n",
    "from torchtext.vocab import GloVe,FastText,CharNGram\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torchtext.datasets.imdb import IMDB\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.1 | packaged by conda-forge | (default, Nov 13 2018, 18:33:04) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_cuda = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda=True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, batch_first=True,fix_length=40,)\n",
    "LABEL = data.Field(sequential=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.datasets.imdb.IMDB"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x7fd027afc0f0>, 'label': <torchtext.data.field.Field object at 0x7fd027afc160>}\n",
      "len(train) 25000\n",
      "vars(train[0]) {'text': ['at', 'first', 'i', \"didn't\", 'think', 'that', 'ben', 'affleck', 'could', 'really', 'pull', 'off', 'a', 'funny', 'christmas', 'movie,,', 'boy', 'was', 'i', 'wrong,', 'my', 'daughter', 'invited', 'me', 'to', 'watch', 'this', 'with', 'her', 'and', 'i', 'was', 'not', 'disappointed', 'at', 'all.', 'james', 'gandolfini', 'was', 'funny,,', 'i', 'really', 'liked', 'christina', 'appelagate,', 'and', 'catherine', \"o'\", 'hara', 'was', 'good', 'too,', 'the', 'storyline', 'is', 'what', 'really', 'sold', 'me,,', 'i', 'mean,,', 'too', 'put', 'up', 'with', 'family,,', 'at', 'the', 'table', 'for', 'people', 'you', 'only', 'hardly', 'see', 'but', 'once', 'or', 'twice', 'a', 'year,,', 'and', 'probably', \"don't\", 'get', 'along', 'with', 'anyway,,', 'you', 'really', 'do', 'need', 'as', 'much', 'alcohol', 'as', \"you're\", 'system', 'can', 'stand', 'to', 'deal', 'with', 'christmas,,', 'so', 'i', 'thought', 'that', 'the', 'premise', 'was', 'good', 'there,', 'buying', 'the', 'family', 'with', '250000', 'dollars,', 'was', 'a', 'little', 'on', 'the', 'far', 'fetched', 'side,,', 'but', 'it', 'turned', 'out', 'to', 'work', 'pretty', 'good', 'for', 'me,,', 'cause', 'it', 'was', 'a', 'riot', 'all', 'the', 'way', 'through,', 'it', 'shows', 'the', 'class', 'struggle', 'of', 'the', 'different', 'families.', 'it', 'has', \"lot's\", 'of', 'funny', 'moments,', 'including', 'embarrassing', 'stuff', 'on', 'the', 'computer', 'for', 'a', 'teenage', 'boy.', 'all', 'in', 'all', 'i', 'loved', 'this', 'movie', 'and', 'will', 'watch', 'it', 'again', 'next', 'christmas', 'or', 'sooner', 'if', 'my', 'daughter', 'wants', 'too.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))\n",
    "print('vars(train[0])', vars(train[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10)\n",
    "LABEL.build_vocab(train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pos': 12500, 'neg': 12500})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x7fd027afc0f0>, 'label': <torchtext.data.field.Field object at 0x7fd027afc160>}\n",
      "len(train) 25000\n",
      "vars(train[0]) {'text': ['at', 'first', 'i', \"didn't\", 'think', 'that', 'ben', 'affleck', 'could', 'really', 'pull', 'off', 'a', 'funny', 'christmas', 'movie,,', 'boy', 'was', 'i', 'wrong,', 'my', 'daughter', 'invited', 'me', 'to', 'watch', 'this', 'with', 'her', 'and', 'i', 'was', 'not', 'disappointed', 'at', 'all.', 'james', 'gandolfini', 'was', 'funny,,', 'i', 'really', 'liked', 'christina', 'appelagate,', 'and', 'catherine', \"o'\", 'hara', 'was', 'good', 'too,', 'the', 'storyline', 'is', 'what', 'really', 'sold', 'me,,', 'i', 'mean,,', 'too', 'put', 'up', 'with', 'family,,', 'at', 'the', 'table', 'for', 'people', 'you', 'only', 'hardly', 'see', 'but', 'once', 'or', 'twice', 'a', 'year,,', 'and', 'probably', \"don't\", 'get', 'along', 'with', 'anyway,,', 'you', 'really', 'do', 'need', 'as', 'much', 'alcohol', 'as', \"you're\", 'system', 'can', 'stand', 'to', 'deal', 'with', 'christmas,,', 'so', 'i', 'thought', 'that', 'the', 'premise', 'was', 'good', 'there,', 'buying', 'the', 'family', 'with', '250000', 'dollars,', 'was', 'a', 'little', 'on', 'the', 'far', 'fetched', 'side,,', 'but', 'it', 'turned', 'out', 'to', 'work', 'pretty', 'good', 'for', 'me,,', 'cause', 'it', 'was', 'a', 'riot', 'all', 'the', 'way', 'through,', 'it', 'shows', 'the', 'class', 'struggle', 'of', 'the', 'different', 'families.', 'it', 'has', \"lot's\", 'of', 'funny', 'moments,', 'including', 'embarrassing', 'stuff', 'on', 'the', 'computer', 'for', 'a', 'teenage', 'boy.', 'all', 'in', 'all', 'i', 'loved', 'this', 'movie', 'and', 'will', 'watch', 'it', 'again', 'next', 'christmas', 'or', 'sooner', 'if', 'my', 'daughter', 'wants', 'too.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))\n",
    "print('vars(train[0])', vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = vars(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['freqs', 'itos', 'stoi', 'vectors'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.7724, -0.1800,  0.2072,  ...,  0.6736,  0.2263, -0.2919],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, device=-1)\n",
    "\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbNet(nn.Module):\n",
    "    def __init__(self,emb_size,hidden_size1,hidden_size2=400):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(emb_size,hidden_size1)\n",
    "        self.fc = nn.Linear(hidden_size2,3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        embeds = self.embedding(x).view(x.size(0),-1)\n",
    "        out = self.fc(embeds)\n",
    "        return F.log_softmax(out,dim=-1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = EmbNet(len(TEXT.vocab.stoi),10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, device=device,shuffle=True)\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , batch in enumerate(data_loader):\n",
    "        text , target = batch.text , batch.label\n",
    "        if is_cuda:\n",
    "            text,target = text.to(device),target.to(device)\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(text)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        \n",
    "        running_loss += F.nll_loss(output,target,size_average=False).item()\n",
    "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = float(running_loss/len(data_loader.dataset))\n",
    "    accuracy = float(100. * running_correct/len(data_loader.dataset))\n",
    "    \n",
    "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walle/miniconda3/envs/pytorch1_py37/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.74 and training accuracy is 12964/25000      51.0\n",
      "validation loss is  0.71 and validation accuracy is 13324/25000      53.0\n",
      "training loss is  0.68 and training accuracy is 14476/25000      57.0\n",
      "validation loss is  0.68 and validation accuracy is 14487/25000      57.0\n",
      "training loss is  0.64 and training accuracy is 15819/25000      63.0\n",
      "validation loss is  0.65 and validation accuracy is 15627/25000      62.0\n",
      "training loss is  0.59 and training accuracy is 16929/25000      67.0\n",
      "validation loss is  0.63 and validation accuracy is 16332/25000      65.0\n",
      "training loss is  0.55 and training accuracy is 17867/25000      71.0\n",
      "validation loss is  0.61 and validation accuracy is 16805/25000      67.0\n",
      "training loss is  0.52 and training accuracy is 18505/25000      74.0\n",
      "validation loss is   0.6 and validation accuracy is 17160/25000      68.0\n",
      "training loss is  0.48 and training accuracy is 19080/25000      76.0\n",
      "validation loss is   0.6 and validation accuracy is 17412/25000      69.0\n",
      "training loss is  0.46 and training accuracy is 19521/25000      78.0\n",
      "validation loss is   0.6 and validation accuracy is 17468/25000      69.0\n",
      "training loss is  0.43 and training accuracy is 19947/25000      79.0\n",
      "validation loss is   0.6 and validation accuracy is 17661/25000      70.0\n"
     ]
    }
   ],
   "source": [
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]\n",
    "\n",
    "for epoch in range(1,10):\n",
    "\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pretrained Glove word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, batch_first=True,fix_length=40,)\n",
    "LABEL = data.Field(sequential=False,)\n",
    "\n",
    "train, test = IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "TEXT.build_vocab(train,test, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10)\n",
    "LABEL.build_vocab(train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbNet(nn.Module):\n",
    "    def __init__(self,emb_size,hidden_size1,hidden_size2=400):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(emb_size,hidden_size1)\n",
    "        self.fc1 = nn.Linear(hidden_size2,3)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        embeds = self.embedding(x).view(x.size(0),-1)\n",
    "        out = self.fc1(embeds)\n",
    "        return F.log_softmax(out,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = EmbNet(len(TEXT.vocab.stoi),300,12000)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.embedding.weight.data = TEXT.vocab.vectors.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(model.parameters(),lr=0.001)\n",
    "optimizer = optim.Adam([ param for param in model.parameters() if param.requires_grad == True],lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=64, device=-1,shuffle=True)\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , batch in enumerate(data_loader):\n",
    "        text , target = batch.text , batch.label\n",
    "        if is_cuda:\n",
    "            text,target = text.to(device),target.to(device)\n",
    "        \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(text)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        \n",
    "        running_loss += F.nll_loss(output,target,size_average=False).item()\n",
    "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = float(running_loss/len(data_loader.dataset))\n",
    "    accuracy = float(100. * running_correct/len(data_loader.dataset))\n",
    "    \n",
    "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.65 and training accuracy is 15797/25000      63.0\n",
      "validation loss is  0.68 and validation accuracy is 16044/25000      64.0\n",
      "training loss is  0.56 and training accuracy is 17743/25000      70.0\n",
      "validation loss is  0.65 and validation accuracy is 16499/25000      65.0\n",
      "training loss is  0.53 and training accuracy is 18355/25000      73.0\n",
      "validation loss is  0.67 and validation accuracy is 16475/25000      65.0\n",
      "training loss is  0.51 and training accuracy is 18761/25000      75.0\n",
      "validation loss is  0.71 and validation accuracy is 16269/25000      65.0\n",
      "training loss is  0.49 and training accuracy is 19036/25000      76.0\n",
      "validation loss is  0.72 and validation accuracy is 16361/25000      65.0\n",
      "training loss is  0.48 and training accuracy is 19249/25000      76.0\n",
      "validation loss is  0.73 and validation accuracy is 16188/25000      64.0\n",
      "training loss is  0.47 and training accuracy is 19384/25000      77.0\n",
      "validation loss is  0.75 and validation accuracy is 16263/25000      65.0\n",
      "training loss is  0.46 and training accuracy is 19619/25000      78.0\n",
      "validation loss is  0.79 and validation accuracy is 16048/25000      64.0\n",
      "training loss is  0.45 and training accuracy is 19626/25000      78.0\n",
      "validation loss is   0.8 and validation accuracy is 16182/25000      64.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,10):\n",
    "\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.45 and training accuracy is 19730/25000      78.0\n",
      "validation loss is   0.8 and validation accuracy is 16167/25000      64.0\n",
      "training loss is  0.44 and training accuracy is 19793/25000      79.0\n",
      "validation loss is  0.83 and validation accuracy is 16130/25000      64.0\n",
      "training loss is  0.44 and training accuracy is 19853/25000      79.0\n",
      "validation loss is  0.84 and validation accuracy is 16004/25000      64.0\n",
      "training loss is  0.43 and training accuracy is 19944/25000      79.0\n",
      "validation loss is  0.86 and validation accuracy is 16052/25000      64.0\n",
      "training loss is  0.43 and training accuracy is 20063/25000      80.0\n",
      "validation loss is  0.86 and validation accuracy is 16088/25000      64.0\n",
      "training loss is  0.42 and training accuracy is 20104/25000      80.0\n",
      "validation loss is  0.88 and validation accuracy is 16038/25000      64.0\n",
      "training loss is  0.42 and training accuracy is 20198/25000      80.0\n",
      "validation loss is  0.88 and validation accuracy is 16019/25000      64.0\n",
      "training loss is  0.41 and training accuracy is 20264/25000      81.0\n",
      "validation loss is   0.9 and validation accuracy is 15978/25000      63.0\n",
      "training loss is  0.41 and training accuracy is 20203/25000      80.0\n",
      "validation loss is  0.92 and validation accuracy is 16008/25000      64.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,10):\n",
    "\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
